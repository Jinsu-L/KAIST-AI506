{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import random\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "## You are always welcome to implement your own function without using external libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Weighted Jaccard similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read M.txt and store col, row, val in a list of dictionaries\n",
    "\n",
    "items = defaultdict(list)\n",
    "\n",
    "with open(f\"M.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        _line = list(map(int, line.rstrip().split(\",\")))\n",
    "        items[_line[0]].append(tuple([_line[1], _line[-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_vec = [[0] * 5 for i in range(3)]\n",
    "\n",
    "for i in range(3):\n",
    "    for user in items[i]:\n",
    "        item_vec[i][user[0]] = user[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {0: [(0, 3), (2, 1), (3, 5)],\n",
       "             1: [(0, 2), (1, 1), (3, 5), (4, 1)],\n",
       "             2: [(0, 5), (2, 4), (3, 1)]})"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 0, 1, 5, 0], [2, 1, 0, 5, 1], [5, 0, 4, 1, 0]]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1,4,1'"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 1. Implement the weighted_jaccard_similarity.\n",
    "\n",
    "def weighted_jaccard_similarity(s1, s2):\n",
    "    ans = 0\n",
    "    #### Implement here ####\n",
    "    sum_of_intersection = 0\n",
    "    sum_of_union = 0\n",
    "    for x_i, y_i in zip(s1, s2):\n",
    "        sum_of_intersection += min(x_i, y_i)\n",
    "        sum_of_union += max(x_i, y_i)\n",
    "    \n",
    "    ans = sum_of_intersection / sum_of_union\n",
    "    \n",
    "    ########################\n",
    "        \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6363636363636364\n",
      "0.1875\n",
      "0.35714285714285715\n"
     ]
    }
   ],
   "source": [
    "print(weighted_jaccard_similarity(item_vec[0], item_vec[1]))\n",
    "print(weighted_jaccard_similarity(item_vec[1], item_vec[2]))\n",
    "print(weighted_jaccard_similarity(item_vec[0], item_vec[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Implement a code that returns shingle per items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {0: [(0, 3), (2, 1), (3, 5)],\n",
       "             1: [(0, 2), (1, 1), (3, 5), (4, 1)],\n",
       "             2: [(0, 5), (2, 4), (3, 1)]})"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 2. Implement build_items_to_shingle_dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in range(1,1+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-function that will be used in the next tasks.\n",
    "# Please implement this function for future use.\n",
    "\n",
    "def get_shingles(items):\n",
    "    shingles = []\n",
    "    \n",
    "    #### Implement here ####\n",
    "    \n",
    "    users = set()\n",
    "    ratings = set()\n",
    "    for item in items.values():\n",
    "        for feedback in item:\n",
    "            users.add(feedback[0])\n",
    "            ratings.add(feedback[1])\n",
    "    \n",
    "    shingles = list(itertools.product(users, ratings))\n",
    "#     key_template = \"{item}_{user}_{rating}\"\n",
    "#     for item_no, item in items.items():\n",
    "#         for feedback in item:\n",
    "#             user_no, rate = feedback\n",
    "#             for i in range(1, rate+1):\n",
    "#                 shingles.append(key_template.format(item=item_no, user=user_no, rating=i))\n",
    "        \n",
    "#     users = defaultdict(int)\n",
    "# #     ratings = set()\n",
    "#     for item in items.values():\n",
    "#         for feedback in item:\n",
    "#             user_no, rate = feedback\n",
    "            \n",
    "#             users[user_no] = max(users[user_no], rate)\n",
    "    \n",
    "#     for user_no, max_rate in users.items():\n",
    "#         for i in range(1, max_rate+1):\n",
    "#                 shingles.append((user_no, i))\n",
    "    \n",
    "    ########################\n",
    "    \n",
    "    return set(shingles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_items_to_shingle_dictionary(items, shingles):\n",
    "    item_to_shingles = {}\n",
    "    \n",
    "    #### Implement here ####\n",
    "    shingle_to_idx = {}\n",
    "    for i, shingle in enumerate(sorted(shingles)):\n",
    "        shingle_to_idx[shingle] = i\n",
    "    \n",
    "    \n",
    "    for item_no, item in items.items():\n",
    "        buf = []\n",
    "        for feedback in item:\n",
    "            user_no, rate = feedback\n",
    "            for i in range(1, rate+1):\n",
    "                buf.append((user_no, i))\n",
    "                \n",
    "        item_to_shingles[item_no] = [shingle_to_idx[i] for i in buf]\n",
    "    \n",
    "    ########################\n",
    "    \n",
    "    \n",
    "    return item_to_shingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "shingles = get_shingles(items)\n",
    "item_to_shingles = build_items_to_shingle_dictionary(items, shingles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3. Implement jaccard_similarity.\n",
    "def jaccard_similarity(s1, s2):\n",
    "    ans = 0\n",
    "    #### Implement here ####\n",
    "    ans = len(s1.intersection(s2)) / len(s1.union(s2))\n",
    "    \n",
    "    ########################\n",
    "        \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6363636363636364\n",
      "0.1875\n",
      "0.35714285714285715\n"
     ]
    }
   ],
   "source": [
    "print(jaccard_similarity(set(item_to_shingles[0]), set(item_to_shingles[1])))\n",
    "print(jaccard_similarity(set(item_to_shingles[1]), set(item_to_shingles[2])))\n",
    "print(jaccard_similarity(set(item_to_shingles[0]), set(item_to_shingles[2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import MovieLens dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov2usr_rate = defaultdict(list)\n",
    "\n",
    "\n",
    "with open(f\"Rating.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        _line = list(map(int, line.rstrip().split(\",\")))\n",
    "        mov2usr_rate[_line[1]].append(tuple([_line[0], _line[-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2movie = defaultdict(str)\n",
    "\n",
    "with open(f\"MovieInfo.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        _line = line.rstrip().split(\",\")\n",
    "        index2movie[int(_line[0])] = _line[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed\n"
     ]
    }
   ],
   "source": [
    "# Check whether your implementation is correct\n",
    "if len(mov2usr_rate) == 10677:\n",
    "    print('Test passed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Get Shingles from the movies (Hint: Reuse the code you implemented in Task 2!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shingles(items):\n",
    "    shingles = []\n",
    "    \n",
    "    #### Implement here ####\n",
    "    \n",
    "    users = defaultdict(int)\n",
    "#     ratings = set()\n",
    "    for item in items.values():\n",
    "        for feedback in item:\n",
    "            user_no, rate = feedback\n",
    "            \n",
    "            users[user_no] = max(users[user_no], rate)\n",
    "    \n",
    "    for user_no, max_rate in users.items():\n",
    "        for i in range(1, max_rate+1):\n",
    "                shingles.append((user_no, i))\n",
    "    \n",
    "    \n",
    "#     print(len(users))\n",
    "#     print(len(ratings))\n",
    "    \n",
    "#     shingles = [tuple(sorted(i)) for i in list(itertools.product(users, ratings))]\n",
    "    \n",
    "    \n",
    "    ########################\n",
    "    \n",
    "    return set(shingles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.207033157348633\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "shingles = get_shingles(mov2usr_rate)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed\n"
     ]
    }
   ],
   "source": [
    "# Check whether your implementation is correct\n",
    "if len(shingles) == 348290:\n",
    "    print('Test passed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Build dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_to_shingles = build_items_to_shingle_dictionary(mov2usr_rate, shingles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed\n"
     ]
    }
   ],
   "source": [
    "# Check whether your implementation is correct\n",
    "if len(item_to_shingles) == 10677 and len(item_to_shingles[0]) == 6997:\n",
    "    print('Test passed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Min-Hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Generate Prime numbers for Universal Hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_prime(n):\n",
    "    for i in range(2,int(np.sqrt(n))+1):\n",
    "        if not n % i:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def generate_prime_numbers(M, N):\n",
    "    primes = []\n",
    "    cnt = 0\n",
    "    n = N + 1\n",
    "    \n",
    "    while cnt < M:\n",
    "        if is_prime(n):\n",
    "            primes.append(n)\n",
    "            cnt += 1\n",
    "        n += 1\n",
    "    return primes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Min Hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 100\n",
    "N = len(shingles)\n",
    "\n",
    "class Hash():\n",
    "    def __init__(self, M, N, primes):\n",
    "        self.M = M\n",
    "        self.N = N\n",
    "        self.primes = primes\n",
    "        \n",
    "        self.a = np.random.choice(np.arange(999,9999), M, replace = False)\n",
    "        self.b = np.random.choice(np.arange(self.N), M, replace = False)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return np.mod(np.mod((self.a * x + self.b), self.primes), self.N)\n",
    "    \n",
    "\n",
    "def min_hash(item_to_shingles, M, N):\n",
    "    C = len(item_to_shingles)\n",
    "\n",
    "    signatures = np.array(np.ones((M, C)) * np.inf, dtype = np.int)\n",
    "    primes = generate_prime_numbers(M, N)\n",
    "    hash_func = Hash(M, N, primes)\n",
    "    \n",
    "    for item_idx, shingle_idxes in tqdm(item_to_shingles.items()):\n",
    "        hash_arr = np.array([hash_func(shingle_idx) for shingle_idx in shingle_idxes])\n",
    "        \n",
    "        sig = np.min(hash_arr, 0)\n",
    "        signatures[np.arange(M), item_idx] = sig\n",
    "\n",
    "    return signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Locality Sensitive Hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Min-Hash based LSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsh(signatures, b, r):\n",
    "    candidatePairs = set()\n",
    "    \n",
    "    M = signatures.shape[0]  # The number of min-hash functions\n",
    "    C = signatures.shape[1]  # The number of movies\n",
    "    \n",
    "    assert M == b * r\n",
    "    \n",
    "    #### Implement here ####\n",
    "    hash_table = dictionary()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ########################\n",
    "    \n",
    "\n",
    "    return candidatePairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1424/1366249128.py:20: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  signatures = np.array(np.ones((M, C)) * np.inf, dtype = np.int)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 10677/10677 [03:14<00:00, 54.78it/s]\n"
     ]
    }
   ],
   "source": [
    "signatures = min_hash(item_to_shingles, M, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsh(signatures, 1, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Compute the precision, recall, and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1424/1366249128.py:20: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  signatures = np.array(np.ones((M, C)) * np.inf, dtype = np.int)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 10677/10677 [03:15<00:00, 54.50it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 10677/10677 [15:56<00:00, 11.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of condition positives: 1319 when s=0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute the number of positives\n",
    "signatures = min_hash(item_to_shingles, M, N)\n",
    "s = 0.4  # threshold\n",
    "numConditionPositives = 1319 # This is the computed result when s=0.4, but I gave it to you to save your time.\n",
    "\n",
    "computeConditionPositives = True # If you want to calculate it, then change it to True. It will take 30 minutes to compute.\n",
    "\n",
    "if computeConditionPositives:\n",
    "    testShingle = defaultdict(set)\n",
    "    numConditionPositives = 0\n",
    "    compareDist = defaultdict(list)\n",
    "    idx2size = defaultdict(int)\n",
    "\n",
    "    for key in index2movie.keys():\n",
    "        testShingle[key] = set(item_to_shingles[key])\n",
    "        \n",
    "    numItems = len(mov2usr_rate.keys())\n",
    "\n",
    "    for i in range(numItems):\n",
    "        shingle1 = testShingle[i]\n",
    "        size1 = len(shingle1)\n",
    "        idx2size[i] = size1\n",
    "        for j in range(i+1, numItems):\n",
    "            shingle2 = testShingle[j]\n",
    "            size2 = len(shingle2)\n",
    "            idx2size[j] = size2\n",
    "            if size2 <= size1:\n",
    "                compareDist[i].append(j)\n",
    "            else:\n",
    "                compareDist[j].append(i)\n",
    "    \n",
    "    for i in tqdm(range(numItems)):\n",
    "        shingle1 = testShingle[i]\n",
    "        size1 = idx2size[i]\n",
    "\n",
    "        for j in compareDist[i]:\n",
    "            size2 = idx2size[j]\n",
    "            if 2 * size1 > 5 * size2:\n",
    "                continue\n",
    "            shingle2 = testShingle[j]\n",
    "            true_sim = jaccard_similarity(shingle1, shingle2)\n",
    "            if true_sim >= s:\n",
    "                numConditionPositives += 1\n",
    "\n",
    "print(f\"The number of condition positives: {numConditionPositives} when s={s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return query_time, precision, recall, F1 score\n",
    "def query_analysis(signatures, b, s, numConditionPositives):\n",
    "    \n",
    "    #### Implement here ####\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ########################\n",
    "    \n",
    "\n",
    "    return query_time, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the list of every divisor of given integer\n",
    "def find_divisors(x):\n",
    "    divisors = list()\n",
    "    for i in range(1, x):\n",
    "        if x % i == 0:\n",
    "            divisors.append(i)\n",
    "    return divisors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_list = find_divisors(M)\n",
    "\n",
    "query_time_list = list()\n",
    "precision_list = list()\n",
    "recall_list = list()\n",
    "f1_list = list()\n",
    "\n",
    "for b in tqdm(b_list):\n",
    "    query_time, precision, recall, f1 = query_analysis(signatures, b, s, numConditionPositives)\n",
    "    query_time_list.append(query_time)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"b: \", b_list)\n",
    "print(\"Query times: \", query_time_list)\n",
    "print(\"Precisions: \", precision_list)\n",
    "print(\"Recalls: \", recall_list)\n",
    "print(\"F1 scores: \", f1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(f\"Query time (s={s})\")\n",
    "plt.xlabel(\"b\")\n",
    "plt.ylabel(\"Query time [sec]\")\n",
    "plt.plot(b_list, query_time_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(f\"Precision (s={s})\")\n",
    "plt.xlabel(\"b\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.plot(b_list, precision_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(f\"Recall (s={s})\")\n",
    "plt.xlabel(\"b\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.plot(b_list, recall_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(f\"F1 Score (s={s})\")\n",
    "plt.xlabel(\"b\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.plot(b_list, f1_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 37 Star Wars: Episode VI - Return of the Jedi (1983)\n",
    "# 1459 Wallace & Gromit: A Grand Day Out (1989)\n",
    "# 96 Toy Story (1995)\n",
    "# 1239 Harry Potter and the Goblet of Fire (2005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Implement any functions here ####\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "######################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
