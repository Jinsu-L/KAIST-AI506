{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Validation of the trained model (CASG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task2Net(\n",
      "  (feature_fc): Linear(in_features=11776, out_features=32, bias=True)\n",
      "  (GConv1): GraphConv(in=32, out=32, normalization=both, activation=None)\n",
      "  (GConv2): GraphConv(in=32, out=48, normalization=both, activation=None)\n",
      "  (GConv3): GraphConv(in=48, out=64, normalization=both, activation=None)\n",
      "  (dropout1): Dropout(p=0.6, inplace=False)\n",
      "  (dropout2): Dropout(p=0.6, inplace=False)\n",
      "  (dropout3): Dropout(p=0.6, inplace=False)\n",
      "  (mix_lstm): LSTM(144, 144, proj_size=72, batch_first=True, bidirectional=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24668/923021939.py:70: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1666642975993/work/torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  query_embeds, pos_embeds, _, logit = model(g, torch.tensor(batched_query).to(device), torch.tensor(labels).to(device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1437, 91.4207\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "# from pytorch_lightning.metrics.functional import accuracy\n",
    "from tqdm import tqdm\n",
    "from Datasets import Task2Dataset\n",
    "from Models.Task2 import Task2Net\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "###########################################################\n",
    "batch_size = 65536\n",
    "lr = 1e-3\n",
    "epoch = 3000\n",
    "scheduler_step = 300\n",
    "scheduler_decay = 0.9\n",
    "\n",
    "resample_rate = 0.35 # dataset에서 label로 쓰일 비율\n",
    "resample_epoch = 10\n",
    "\n",
    "save_folder = \"./GCN_3L_CASG\"\n",
    "\n",
    "###########################################################\n",
    "\n",
    "dataset = Task2Dataset(\"Dataset/\")\n",
    "dataset.resample(resample_rate)\n",
    "g = dataset.g.to(device)\n",
    "train_g = dataset.train_g.to(device)\n",
    "\n",
    "train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "model = Task2Net(dataset.g.to(device)).to(device)\n",
    "\n",
    "# create optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step, gamma=scheduler_decay)\n",
    "\n",
    "# Our model\n",
    "checkpoint = torch.load('CASG_model_0.1437.tar')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "print(model)\n",
    "\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "for itemset_id, query, pos, neg, query_items, lengths in train_dataloader:\n",
    "    pass\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    labels = []\n",
    "    batched_query = []\n",
    "    query_items = []\n",
    "    lengths = []\n",
    "    for itemset_id, querys in dataset.valid_itemset_items.items():\n",
    "        query = np.zeros(dataset.n_items, dtype=np.float32)\n",
    "        label = dataset.valid_itemset_label[itemset_id]\n",
    "        query[querys] = 1\n",
    "\n",
    "        batched_query.append(query)\n",
    "        labels.append(label)\n",
    "        query_items.append(querys + [0 for _ in range(5 - len(querys))])\n",
    "        lengths.append(len(querys))\n",
    "\n",
    "    # import pdb; pdb.set_trace()\n",
    "    query_embeds, pos_embeds, _, logit = model(g, torch.tensor(batched_query).to(device), torch.tensor(labels).to(device),\n",
    "                                                       neg.to(device), torch.tensor(query_items).to(device),\n",
    "                                                       torch.tensor(lengths).to(device))\n",
    "    valid_loss = ce_loss(logit, torch.tensor(labels).to(device))\n",
    "\n",
    "    scores = torch.topk(logit, 100).indices.detach().cpu().numpy()\n",
    "    submit = []\n",
    "    ranking_check = []\n",
    "    for top100, label in zip(scores, labels):\n",
    "        if label not in top100:\n",
    "            ranking_check.append(101)\n",
    "            continue\n",
    "        for i in range(len(top100)):\n",
    "            if label == top100[i]:\n",
    "                ranking_check.append(i+1)\n",
    "                break\n",
    "        string = str(label)\n",
    "        for i in top100:\n",
    "            string += f',{i}'\n",
    "        submit.append(string)\n",
    "    acc = sum([label in top100 for top100, label in zip(scores, labels)]) / len(scores)\n",
    "    print(f\"{acc:.4f}, {sum(ranking_check)/len(ranking_check):.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Test Query - Answer Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "# from pytorch_lightning.metrics.functional import accuracy\n",
    "from tqdm import tqdm\n",
    "from Datasets import Task2Dataset\n",
    "from Models.Task2 import Task2Net\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "###########################################################\n",
    "batch_size = 65536\n",
    "lr = 1e-3\n",
    "epoch = 3000\n",
    "scheduler_step = 300\n",
    "scheduler_decay = 0.9\n",
    "\n",
    "resample_rate = 0.35 # dataset에서 label로 쓰일 비율\n",
    "resample_epoch = 10\n",
    "\n",
    "save_folder = \"./GCN_3L_CASG\"\n",
    "\n",
    "###########################################################\n",
    "\n",
    "dataset = Task2Dataset(\"Dataset/\")\n",
    "dataset.resample(resample_rate)\n",
    "g = dataset.g.to(device)\n",
    "train_g = dataset.train_g.to(device)\n",
    "\n",
    "train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "model = Task2Net(dataset.g.to(device)).to(device)\n",
    "\n",
    "# create optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step, gamma=scheduler_decay)\n",
    "\n",
    "# Our model\n",
    "checkpoint = torch.load('CASG_model_0.1437.tar')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "print(model)\n",
    "\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "for itemset_id, query, pos, neg, query_items, lengths in train_dataloader:\n",
    "    pass\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    labels = []\n",
    "    batched_query = []\n",
    "    query_items = []\n",
    "    lengths = []\n",
    "    for itemset_id, querys in dataset.test_itemset_items.items():\n",
    "        query = np.zeros(dataset.n_items, dtype=np.float32)\n",
    "        label = itemset_id\n",
    "        query[querys] = 1\n",
    "\n",
    "        batched_query.append(query)\n",
    "        labels.append(label)\n",
    "        query_items.append(querys + [0 for _ in range(5 - len(querys))])\n",
    "        lengths.append(len(querys))\n",
    "\n",
    "    # import pdb; pdb.set_trace()\n",
    "    query_embeds, pos_embeds, _, logit = model(g, torch.tensor(batched_query).to(device), torch.tensor(labels).to(device),\n",
    "                                                       neg.to(device), torch.tensor(query_items).to(device),\n",
    "                                                       torch.tensor(lengths).to(device))\n",
    "    valid_loss = ce_loss(logit, torch.tensor(labels).to(device))\n",
    "\n",
    "    scores = torch.topk(logit, 100).indices.detach().cpu().numpy()\n",
    "    submit = []\n",
    "    ranking_check = []\n",
    "    for top100, label in zip(scores, labels):\n",
    "        string = str(label)\n",
    "        for i in top100:\n",
    "            string += f',{i}'\n",
    "        submit.append(string)\n",
    "    with open('./itemset_item_test_prediction.csv', 'w') as f:\n",
    "        for i in submit:\n",
    "            f.write(f'{i}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TSDAE_cuda_11.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
